{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_preprocessing_script.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM-QTyulHg0T"
      },
      "source": [
        "Preprocessing script for images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px-9NSs8HrU_"
      },
      "source": [
        "First, assign unique names to images using the csv created in the R preprocessing script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-3RmWhtIHA8"
      },
      "source": [
        "\"\"\"\n",
        "Created on Thu Nov 12, 2020\n",
        "\n",
        "@author: Sophia Marthine Kleist Karlson\n",
        "\"\"\"\n",
        "## Script that renames drawings to unique names and puts them all in the same folder\n",
        "\n",
        "\n",
        "# import the necessary packages\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# set path\n",
        "path = \"C:/Users/Sophia/Documents/Social Transmission Study/Analysis of drawings/\" #this script is run locally on my computer, hence this path\n",
        "os.chdir(path)\n",
        "print(path)\n",
        "\n",
        "# create folder for all images to be put in\n",
        "if not os.path.exists('all_drawings'):\n",
        "    os.makedirs('all_drawings')\n",
        "\n",
        "# Import the csv file with image paths and unique names\n",
        "Drawing_IDs = pd.read_csv('Drawing_IDs.csv')\n",
        "\n",
        "# make the image path column to a list\n",
        "image_path_list = Drawing_IDs[[\"image_path\"]]\n",
        "image_path_list = image_path_list[\"image_path\"].tolist()\n",
        "\n",
        "# make the image ID column to a list\n",
        "image_ID_list = Drawing_IDs[[\"Drawing_ID\"]]\n",
        "image_ID_list = image_ID_list[\"Drawing_ID\"].tolist()\n",
        "\n",
        "# Loop that reads the image paths and saves them into the all_drawings folder with their unique names\n",
        "for i in range(len(image_ID_list)):\n",
        "    drawing = cv2.imread(image_path_list[i])\n",
        "    drawing_ID = \"all_drawings/\" + image_ID_list[i] + \".png\"\n",
        "    cv2.imwrite(drawing_ID, drawing)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NCzBtuWYM5a"
      },
      "source": [
        "Upload all images to google colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8vICtUmIgKj"
      },
      "source": [
        "Now we resize all images to 400x400px"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhMYunCrHX1y"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "#do we actually need more modules like pandas or numpy? e.g. for .format() and .sort()\n",
        "\n",
        " \n",
        "# define path where all drawings are\n",
        "path = \"/content/\" \n",
        "img_list = glob.glob(path + \"*.png\")\n",
        "img_list.sort()\n",
        "\n",
        "id = []\n",
        "\n",
        "if not os.path.exists('resized'):\n",
        "    os.makedirs('resized')\n",
        "\n",
        "for i in range(len(img_list)):\n",
        "  id.append(re.findall('/content/(Chain_\\d+_Gen_\\d+_Cond_\\d+_Source_\\d+).png', img_list[i])[0])\n",
        "  src = cv2.imread(img_list[i], cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  # set a new height and width in pixels\n",
        "  new_height = 400\n",
        "  new_width = 400\n",
        "\n",
        "  # dsize\n",
        "  dsize = (new_width, new_height)\n",
        "\n",
        "  # resize image\n",
        "  output = cv2.resize(src, dsize)\n",
        "\n",
        "  cv2.imwrite('/content/resized/{}.png'.format(id[i]), output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYlG3A-7Hf5N"
      },
      "source": [
        "The resized images are blurred using cv.blur(), using the averaging function, and then converted to jpeg2000 format, the file sizes of which are put into a dataframe and saved as csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKwt8apyIwy7"
      },
      "source": [
        "# import the necessary packages\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "#import cv2 as cv\n",
        "\n",
        "\n",
        "# Define function\n",
        "def complexity_comparison_function(img_list):\n",
        "  \n",
        "  # make directory to put jp2 files\n",
        "  if not os.path.exists('jpeg_compressed_files'):\n",
        "    os.makedirs('jpeg_compressed_files')\n",
        "    \n",
        "  # prepare dataframe\n",
        "  columns = ['Stim_ID', 'Complexity_original', 'Complexity_convolution']\n",
        "  index = np.arange(0)\n",
        "  Complexity_comparison_data = pd.DataFrame(columns=columns, index = index)\n",
        "\n",
        "  # list for id's\n",
        "  id = []\n",
        "  \n",
        "  # convert png to jp2\n",
        "  for i in range(len(img_list)):\n",
        "    print(img_list) \n",
        "    id.append(re.findall('/content/resized/(Chain_\\d+_Gen_\\d+_Cond_\\d+_Source_\\d+).png', img_list[i])[0]) \n",
        "    \n",
        "    #complexity of original:\n",
        "    img_original = Image.open(img_list[i])\n",
        "    img_original.convert(\"RGBA\").save(\"jpeg_compressed_files_comparison/Original_{}.jp2\".format(id[i]), 'JPEG2000', quality_mode='dB', quality_layers=[80])\n",
        "    \n",
        "    # read image for blurring\n",
        "    img_blur = cv.imread(img_list[i])\n",
        "\n",
        "    # convolution\n",
        "    kernel = np.ones((5,5),np.float32)/25\n",
        "    dst = cv.filter2D(img_blur,-1,kernel)\n",
        "    cv2.imwrite('/content/Convolution_{}.png'.format(id[i]), dst)\n",
        "\n",
        "    # jpeg2000 convertion of blurred images\n",
        "    img_convolution = Image.open(\"/content/Convolution_{}.png\".format(id[i]))\n",
        "    img_convolution.convert(\"RGBA\").save(\"jpeg_compressed_files_comparison/Convolution_{}.jp2\".format(id[i]), 'JPEG2000', quality_mode='dB', quality_layers=[80])\n",
        "\n",
        "  # list of original jp2 files\n",
        "  img_jp2_original = glob.glob(\"jpeg_compressed_files_comparison/Original_*.jp2\")\n",
        "  img_jp2_original.sort() #important! Else the IDs and complexity scores won't match\n",
        "\n",
        "  # list of convolution jp2 files\n",
        "  img_jp2_convolution = glob.glob(\"jpeg_compressed_files_comparison/Convolution_*.jp2\")\n",
        "  img_jp2_convolution.sort()\n",
        "\n",
        "  # save size and ID to dataframe\n",
        "  for i in range(len(img_jp2_original)): \n",
        "    size_original = (Path(img_jp2_original[i]).stat().st_size)\n",
        "    size_convolution = (Path(img_jp2_convolution[i]).stat().st_size)\n",
        "\n",
        "    Complexity_comparison_data = Complexity_comparison_data.append({\n",
        "      'Stim_ID': id[i],\n",
        "      'Complexity_original': size_original, \n",
        "      'Complexity_convolution': size_convolution\n",
        "    }, ignore_index=True)\n",
        "  return Complexity_comparison_data\n",
        "\n",
        "\n",
        "# define path where all drawings are\n",
        "path = \"/content/resized/\" \n",
        "files = glob.glob(path + \"*.png\")\n",
        "files.sort() #important! Else the IDs and complexity scores won't match\n",
        "\n",
        "# run function on all drawings\n",
        "complexity_comparison_data = complexity_comparison_function(files)\n",
        "\n",
        "# print complexity scores and ID's\n",
        "print(complexity_comparison_data)\n",
        "\n",
        "# prepare logfilename and save\n",
        "logfilename = \"complexity_comparison.csv\"\n",
        "complexity_comparison_data.to_csv(logfilename)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}